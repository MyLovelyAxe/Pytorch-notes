{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d72b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2adfeb4",
   "metadata": {},
   "source": [
    "#### LSTM: Long Short-Term Memory\n",
    "<font size = 2>\n",
    "    \n",
    "The memory unit in RNN is **short-term**, which can only remember some adjacent information. If want to predict next information based on long-term previously memory, RNN will not perform well. To make longer memory, introduce **LSTM**, i.e. **Long Short-Term Memory**. The basicly intrisic structure is shown as below:\n",
    "    \n",
    "<div>\n",
    "<img src = 'LSTM_1.png' style = 'zoom:40%'/>\n",
    "</div>\n",
    "    \n",
    "The **LSTM** contains 4 main elements: **forget-gate**, **update-gate**, **updating-state-cell-part** and **output-gate**.\n",
    "    \n",
    "$C_{t-1}$\n",
    "    \n",
    "    previous state cell, containing input memory information from previous layer\n",
    "    \n",
    "$C_{t}$\n",
    "    \n",
    "    state cell after current LSTM unit\n",
    "    \n",
    "$\\sigma$ and $tanh$\n",
    "    \n",
    "    compose the gates of different elements, which function as inspection and filtering\n",
    "$x_{t}$\n",
    "    \n",
    "    current input\n",
    "    \n",
    "$h_{t-1}$\n",
    "    \n",
    "    output memory from previous layer\n",
    "    \n",
    "$h_{t}$\n",
    "    \n",
    "    output memory after current LSTM unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbefb768",
   "metadata": {},
   "source": [
    "#### Elements of LSTM\n",
    "<font size = 2>\n",
    "    \n",
    "1) Forget Gate:\n",
    "  \n",
    "$f_{t}$:\n",
    "    \n",
    "    a number between 0 and 1 representing which values to be remembered/forgotten from sigmoid activation function\n",
    "    \n",
    "$h_{t-1}$:\n",
    "    \n",
    "    output memory from previous layer/time epoch\n",
    "    \n",
    "$x_{t}$:\n",
    "    \n",
    "    current input\n",
    "    \n",
    "<div>\n",
    "<img src = 'LSTM_ForgetGate.png' style = 'zoom:67%'/>\n",
    "</div>\n",
    "    \n",
    "$$f_{t} = \\sigma (W_{f} \\cdot [h_{t-1}, x_{t}] + b_{f})$$\n",
    "    \n",
    "with $W_{f}$ and $b_{f}$ are weights and bias for **forget gate**.\n",
    "\n",
    "2) Update Gate:\n",
    "    \n",
    "$i_{t}$: input gate\n",
    "    \n",
    "    decides which values are updated\n",
    "    \n",
    "$\\tilde{C}_{t}$: candidate updating\n",
    "    \n",
    "    creates a vector of new candidate values that could be  added to the state, i.e. the content in from input and previous output memory which maybe updated into state cell\n",
    "    \n",
    "<div>\n",
    "<img src = 'LSTM_UpdateGate.png' style = 'zoom:70%'/>\n",
    "</div>\n",
    " \n",
    "$$i_{t} = \\sigma (W_{i} \\cdot [h_{t-1}, x_{t}] + b_{i})$$\n",
    "    \n",
    "$$\\tilde{C}_{t} = tanh (W_{C} \\cdot [h_{t-1}, x_{t}] + b_{C})$$\n",
    "    \n",
    "with $W_{i}$ and $b_{i}$ are weights and bias for **input gate** and $W_{C}$ and $b_{C}$ for **candidate updating**\n",
    "    \n",
    "3) Updating State Cell:\n",
    "    \n",
    "<div>\n",
    "<img src = 'LSTM_UpdatingStateCell.png' style = 'zoom:70%'/>\n",
    "</div>\n",
    "    \n",
    "$$C_{t} = f_{t} \\cdot C_{t-1} + i_{t} \\cdot \\tilde{C}_{t}$$\n",
    "    \n",
    "$f_{t} \\cdot C_{t-1}$:\n",
    "    \n",
    "    the content we decided to forget/remember from previous state cell\n",
    "    \n",
    "$i_{t} \\cdot \\tilde{C}_{t}$:\n",
    "    \n",
    "    the content we want to update/add to state cell from input and previous output memory\n",
    "    \n",
    "4) Output Gate:\n",
    "    \n",
    "$o_{t}$:\n",
    "    \n",
    "    the part decided to output\n",
    "    \n",
    "$tanh(C_{t})$:\n",
    "    \n",
    "    the content from state cell decided to output\n",
    "    \n",
    "<div>\n",
    "<img src = 'LSTM_OutputGate.png' style = 'zoom:71%'/>\n",
    "</div>\n",
    "\n",
    "$$o_{t} = \\sigma (W_{o} \\cdot [h_{t-1}, x_{t}] + b_{o})$$\n",
    "    \n",
    "$$h_{t} = o_{t} \\cdot tanh(C_{t})$$\n",
    "    \n",
    "(ps:Details are presented in ML-L.20-RNNs II)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97219ac2",
   "metadata": {},
   "source": [
    "#### How LSTM Improves Gradient Vanishing(suspended)\n",
    "<font size = 2>\n",
    "    \n",
    "In RNN, The presence of gradient vashing and gradient exploding blames on the partial differentiation between adjacent short-term memory $h_{t}$ and $h_{t-1}$(Check notes in RNN.ipynb):\n",
    "    \n",
    "$$ \\frac{\\partial{E_{t}}}{\\partial{W_{hh}}} = \\sum^{t}_{i} \\frac{\\partial{E_{t}}}{\\partial{y_{t}}} \\frac{\\partial{y_{t}}}{\\partial{h_{t}}} \\frac{\\partial{h_{t}}}{\\partial{h_{i}}} \\frac{\\partial{h_{i}}}{\\partial{W_{hh}}} $$\n",
    "    \n",
    "$$\\frac{\\partial{h_{t}}}{\\partial{h_{i}}} = \\prod^{t-1}_{k=i} diag(f^{â€™}_{w} (x@W_{xh} + h_{k}@W_{hh})) W_{hh}$$\n",
    "    \n",
    "Accumulated product of memory weights $W_{hh}$ result in gradient vanishing or exploding.\n",
    "    \n",
    "In conclusion, gradient vanishing and exploding happen during partial differentiation between adjacent memory weights which are represented as **state cell** $C_{t}$ and $C_{t-1}$ in LSTM. So the reason why LSTM can improve gradient vanishing lies in the following part of LSTM's gradients(gradient exploding can be individually imporved by **gradient clipping**, Check RNN_sin(x)_GradientExploding_solved.py):\n",
    "    \n",
    "$$\\frac{\\mathrm{d} C_{t}}{\\mathrm{d} t} = $$\n",
    "    \n",
    "Due to current state cell $C_{t}$ is calculated as:\n",
    "\n",
    "$$C_{t} = f_{t} \\cdot C_{t-1} + i_{t} \\cdot \\tilde{C}_{t}$$\n",
    "    \n",
    "The gradient of $C_{t}$ is combined with 4 parts:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec0103",
   "metadata": {},
   "source": [
    "#### nn.LSTM( )\n",
    "<font size = 2>\n",
    "    \n",
    "The formulation of gates and parts in nn.LSTM() is similar to original LSTM. However, in order to be integrated into code, there are some adjustments:\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "i_{t} &= \\sigma (W_{ii} x_{t} + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "f_{t} &= \\sigma (W_{if} x_{t} + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "g_{t} &= tanh (W_{ig} x_{t} + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "o_{t} &= \\sigma (W_{io} x_{t} + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "c_{t} &= f_{t} \\odot c_{t-1} + i_{t} \\cdot g_{t} \\\\\n",
    "h_{t} &= o_{t} \\odot tanh(c_{t})\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "    \n",
    "where $h_{t}$ is the hidden state at time t, $c_{t}$ is the cell state at time t, $x_{t}$ is the input at time t, $h_{t-1}$ is the hidden state of the layer at time t-1 or the initial hidden state at time 0, and $i_{t}$, $f_{t}$, $g_{t}$, $o_{t}$ are the input, forget, cell, and output gates, respectively. $\\sigma$ is the sigmoid function, and $\\odot$ is the Hadamard product.\n",
    "    \n",
    "**The parameters in LSTM:**\n",
    "    \n",
    "    LSTM.weight_ih_l:  (W_ii|W_if|W_ig|W_io)   shape: [4*hidden_len, feature_en]\n",
    "    LSTM.weight_hh_l:  (W_hi|W_hf|W_hg|W_ho)   shape: [4*hidden_len, feature_en]\n",
    "    LSTM.bias_ih_l:    (b_ii|b_if|b_ig|b_io)   shape: [4*hidden_len]\n",
    "    LSTM.bias_hh_l:    (b_hi|b_hf|b_hg|b_ho)   shape: [4*hidden_len]\n",
    "    \n",
    "(ps: 'l' means num_layers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82d77f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])\n",
      "\n",
      "weight_ih_l0: torch.Size([200, 100])\n",
      "weight_hh_l0: torch.Size([200, 50])\n",
      "bias_ih_l0: torch.Size([200])\n",
      "bias_hh_l0 torch.Size([200])\n",
      "\n",
      "torch.Size([10, 3, 50])\n",
      "torch.Size([1, 3, 50])\n",
      "torch.Size([1, 3, 50])\n"
     ]
    }
   ],
   "source": [
    "'''Single Layer nn.LSTM'''\n",
    "#create a network:\n",
    "#para: input_size -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "#para: num_layers\n",
    "lstm = nn.LSTM(input_size = 100, hidden_size = 50, num_layers = 1)\n",
    "para = lstm._parameters.keys()\n",
    "print(para)\n",
    "print()\n",
    "#weight_ih_l0:  [4*hidden_len,feature_len]\n",
    "print('weight_ih_l0:',lstm.weight_ih_l0.shape)\n",
    "#weight_hh_l0:  [4*hidden_len,feature_len]\n",
    "print('weight_hh_l0:',lstm.weight_hh_l0.shape)\n",
    "#bias_ih_l0:    [4*hidden_len]\n",
    "print('bias_ih_l0:', lstm.bias_ih_l0.shape)\n",
    "#bias_hh_l0:    [4*hidden_len]\n",
    "print('bias_hh_l0',lstm.bias_hh_l0.shape)\n",
    "print()\n",
    "\n",
    "#x: [seq_len,batch,feature_len]\n",
    "x = torch.randn(10,3,100)\n",
    "#h: [num_layers,batch,hidden_len]\n",
    "h = torch.rand(1,3,50)\n",
    "#c: [num_layers,batch,hidden_len]\n",
    "c = torch.rand(1,3,50)\n",
    "\n",
    "#h and c are combined as a tuple to input\n",
    "out, (h,c) = lstm(x,(h,c))\n",
    "#out is stacked result of h_t\n",
    "#out: [seq_len,batch,hidden_len]\n",
    "print(out.size())\n",
    "#h is memory of the last time t\n",
    "#h: [num_layers,batch,hidden_len]\n",
    "print(h.size())\n",
    "#c is state cell of the last time t\n",
    "#c: [num_layers,batch,hidden_len]\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a4192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', 'weight_ih_l1', 'weight_hh_l1', 'bias_ih_l1', 'bias_hh_l1', 'weight_ih_l2', 'weight_hh_l2', 'bias_ih_l2', 'bias_hh_l2'])\n",
      "\n",
      "torch.Size([10, 3, 50])\n",
      "torch.Size([3, 3, 50])\n",
      "torch.Size([3, 3, 50])\n"
     ]
    }
   ],
   "source": [
    "'''Multi-Layer nn.LSTM'''\n",
    "#create a network:\n",
    "#para: input_size -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "#para: num_layers\n",
    "#latter layer takes output of former layer as input\n",
    "multi_lstm = nn.LSTM(input_size = 100, hidden_size = 50, num_layers = 3)\n",
    "multi_para = multi_lstm._parameters.keys()\n",
    "print(multi_para)\n",
    "print()\n",
    "\n",
    "#multi_x: [seq_len,batch,feature_len]\n",
    "#multi_h and multi_c are defaultly set as 0 if not provided\n",
    "multi_x = torch.randn(10,3,100)\n",
    "\n",
    "out, (h,c) = multi_lstm(multi_x)\n",
    "#out is stacked result of h_t\n",
    "#out: [seq_len,batch,hidden_len]\n",
    "print(out.size())\n",
    "#h is memory of the last time t\n",
    "#h: [num_layers,batch,hidden_len]\n",
    "print(h.size())\n",
    "#c is state cell of the last time t\n",
    "#c: [num_layers,batch,hidden_len]\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec2541",
   "metadata": {},
   "source": [
    "#### nn.LSTMCell( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5428971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "'''Single Layer nn.LSTMCell'''\n",
    "#nn.LSTMCell() is similar with nn.RNNCell()\n",
    "#only operate on single one time epoch, manually offering of input is needed\n",
    "#the output of it is current output memory h_t and current state cell c_t\n",
    "#create a network:\n",
    "#para: input_size -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "#no para of 'num_layers', or reports an error\n",
    "lstm_cell = nn.LSTMCell(input_size = 100, hidden_size = 20)\n",
    "#c_t:  [batch,hidden_len]\n",
    "c_t = torch.randn(3,20)\n",
    "#h_t:  [batch,hidden_len]\n",
    "h_t = torch.randn(3,20)\n",
    "#x:    [seq_len,batch,feature_len]\n",
    "x = torch.randn(10,3,100)\n",
    "#manually offer input\n",
    "for x_t in x:\n",
    "    #x_t:  [batch,feature_len]\n",
    "    (h,c) = lstm_cell(x_t,(h_t,c_t))\n",
    "print(h.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263a4ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "'''Multi-Layer nn.LSTMCell'''\n",
    "#multi-layer nn.LSTMCell needs to be composed by user\n",
    "#latter layer takes the output of former layer as input\n",
    "#pay attention to dimension\n",
    "#create a network:\n",
    "#para: input_size -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "#no para of 'num_layers', or reports an error\n",
    "\n",
    "#input of lstm_cell_1:   [batch, feature_len]   -> [b,100]\n",
    "#output of lstm_cell_1:  [batch, hidden_len_1]  -> [b,50]\n",
    "lstm_cell_1 = nn.LSTMCell(input_size = 100, hidden_size = 50)\n",
    "#lstm_cell_2 takes the output of lstm_cell_1 as input\n",
    "#input of lstm_cell_2:   [batch, hidden_len_1]  -> [b,50]\n",
    "#output of lstm_cell_2:  [batch, hidden_len_2]  -> [b,20]\n",
    "lstm_cell_2 = nn.LSTMCell(input_size = 50, hidden_size = 20)\n",
    "\n",
    "#c_t:  [batch,hidden_len]\n",
    "c_t_1 = torch.randn(3,50)\n",
    "c_t_2 = torch.randn(3,20)\n",
    "#h_t:  [batch,hidden_len]\n",
    "h_t_1 = torch.randn(3,50)\n",
    "h_t_2 = torch.randn(3,20)\n",
    "#x:    [seq_len,batch,feature_len]\n",
    "x = torch.randn(10,3,100)\n",
    "\n",
    "#manually offer input\n",
    "for x_t in x:\n",
    "    #x_t:  [batch,feature_len]\n",
    "    (h_t_1,c_t_1) = lstm_cell_1(x_t,(h_t_1,c_t_1))\n",
    "    (h_t_2,c_t_2) = lstm_cell_2(h_t_1,(h_t_2,c_t_2))\n",
    "print(h_t_2.shape)\n",
    "print(c_t_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33022c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
