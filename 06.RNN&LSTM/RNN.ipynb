{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24b6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af1026",
   "metadata": {},
   "source": [
    "#### Representation of Time Sequence\n",
    "<font size = 2>\n",
    "    \n",
    "The image below simulates the reading/input of a situation:\n",
    "    \n",
    "3 sentences with 100 words each and the identity of each word is shown in 50-dimensional vector.\n",
    "    \n",
    "This situation can be represented as:\n",
    "    \n",
    "    [word_num_in_single_sentence, sentence_num, word_vector] = [100,3,50]\n",
    "    \n",
    "The representation is to shown the process of reading/input sentences simultaneously, i.e. read a sentence one word by one word, but read several sentences at the same time (parallel process of data). And in time sequence, read one word in each time epoch, so **word_num_in_single_sentence** can substitute **time** here.\n",
    "    \n",
    "<div>\n",
    "<img src = \"TimeSequence.png\" style = \"zoom:30%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e02fa",
   "metadata": {},
   "source": [
    "#### RNN Structure\n",
    "<font size = 2>\n",
    "    \n",
    "The **weights** and **bias** are sharing in RNN: weights for input $W_{xh}$ and weights for memory $W_{hh}$ (bias neglected here).\n",
    "\n",
    "The initial memory $h_{0}$ is set to be 0. And each memory $h_{t}$ after each time $t$ epoch will be updated as:\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "h_{t} &= f_{w} (x@W_{xh} + h_{t-1}@W_{hh}) \\\\\n",
    "&= tanh(x@W_{xh} + h_{t-1}@W_{hh})\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "    \n",
    "where $tanh()$ is the activation function used in RNN. And the $h_{t}$ will be as new initial memory of next time epoch.\n",
    "\n",
    "<div>\n",
    "<img src = 'RNN_1.png' style = 'zoom:40%'/>\n",
    "</div>\n",
    "    \n",
    "    \n",
    "Each time epoch $t$ also has its own output $y_{t}$ given by weights for output $W_{hy}$:\n",
    "    \n",
    "$$ y_{t} = h_{t}@W_{hy} $$\n",
    "    \n",
    "<div>\n",
    "<img src = 'RNN_2.png' style = 'zoom:40%'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319df13",
   "metadata": {},
   "source": [
    "#### Gradients of RNN\n",
    "<font size = 2>\n",
    "    \n",
    "How to get the gradient of weights for memory $W_{hh}$?\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "grad(W_{hh}) &= \\frac{\\partial{E_{t}}}{\\partial{W_{hh}}} \\\\\n",
    "&= \\frac{\\partial{E_{t}}}{\\partial{W^{0}_{hh}}} + \\frac{\\partial{E_{t}}}{\\partial{W^{1}_{hh}}} + ... + \\frac{\\partial{E_{t}}}{\\partial{W^{t}_{hh}}} \\\\\n",
    "&= \\sum^{t}_{i} \\frac{\\partial{E_{t}}}{\\partial{W^{i}_{hh}}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "    \n",
    "Take all weights $W_{hh}$ for memory of all time epoch $t$ and sum up. $E_{t}$ is Error function for time $t$.\n",
    "    \n",
    "<div>\n",
    "<img src = 'RNN_3.png' style = 'zoom:40%'>\n",
    "</div>\n",
    "    \n",
    "Due to the formular of current memory $h_{t}$ and output $y_{t}$ which is shown in last section:\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "h_{t} &= f_{w} (x@W_{xh} + h_{t-1}@W_{hh}) \\\\\n",
    "&= tanh(x@W_{xh} + h_{t-1}@W_{hh})\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "    \n",
    "$$ y_{t} = h_{t}@W_{hy} $$\n",
    "\n",
    "and chain rule of taking gradients. We can get:\n",
    "    \n",
    "$$ \\frac{\\partial{E_{t}}}{\\partial{W_{hh}}} = \\sum^{t}_{i} \\frac{\\partial{E_{t}}}{\\partial{y_{t}}} \\frac{\\partial{y_{t}}}{\\partial{h_{t}}} \\frac{\\partial{h_{t}}}{\\partial{h_{i}}} \\frac{\\partial{h_{i}}}{\\partial{W_{hh}}} $$\n",
    "  \n",
    "The parts of the formular above can be obtained separately:\n",
    "\n",
    "1) The gradient of error function $E_{t}$ in time epoch $t$ w.r.t the current output $y_{t}$:\n",
    "    \n",
    "(For example, we take error function as least square error)\n",
    "    \n",
    "$$ \\frac{\\partial{E_{t}}}{\\partial{y_{t}}} =  \\frac{\\partial{\\frac{1}{2} (y_{t} - target)^{2}}}{\\partial{y_{t}}} $$\n",
    "    \n",
    "2) The gradient of current output $y_{t}$ w.r.t current memory $h_{t}$:\n",
    "    \n",
    "$$ \\frac{\\partial{y_{t}}}{\\partial{h_{t}}} = W_{hy} $$\n",
    "    \n",
    "3) The gradient of current memory $h_{t}$ w.r.t history memory $h_{i}$ on time epoch $i$:\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{h_{t}}}{\\partial{h_{i}}} &= \\frac{\\partial{h_{t}}}{\\partial{h_{t-1}}} \\frac{\\partial{h_{t-1}}}{\\partial{h_{t-2}}} ... \\frac{\\partial{h_{i+1}}}{\\partial{h_{i}}} \\\\\n",
    "&= \\prod^{t-1}_{k=i} \\frac{\\partial{h_{k+1}}}{\\partial{h_{k}}} \\\\\n",
    "&= \\prod^{t-1}_{k=i} \\frac{\\partial{f_{w} (x@W_{xh} + h_{k}@W_{hh})}}{\\partial{h_{k}}} \\\\\n",
    "&= \\prod^{t-1}_{k=i} \\frac{\\partial{f_{w} (x@W_{xh} + h_{k}@W_{hh})}}{\\partial{(x@W_{xh} + h_{k}@W_{hh})}} \\frac{\\partial{(x@W_{xh} + h_{k}@W_{hh})}}{\\partial{h_{k}}} \\\\\n",
    "&= \\prod^{t-1}_{k=i} diag(f^{’}_{w} (x@W_{xh} + h_{k}@W_{hh})) W_{hh}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "    \n",
    "The $diag()$ is just a representation.\n",
    "    \n",
    "4) The gradient of history memory $h_{i}$ on time epoch $i$ w.r.t memory weights $W_{hh}$:\n",
    "    \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{h_{i}}}{\\partial{W_{hh}}} &= \\frac{\\partial{f_{w} (x@W_{xh} + h_{i-1}@W_{hh})}}{\\partial{W_{hh}}} \\\\\n",
    "&= \\frac{\\partial{f_{w} (x@W_{xh} + h_{i-1}@W_{hh})}}{\\partial{(x@W_{xh} + h_{i-1}@W_{hh})}} \\frac{\\partial{(x@W_{xh} + h_{i-1}@W_{hh})}}{\\partial{W_{hh}}} \\\\\n",
    "&= f^{’}_{w} (x@W_{xh} + h_{i-1}@W_{hh}) h_{i-1}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8cca4e",
   "metadata": {},
   "source": [
    "#### Shape of Instances\n",
    "<font size = 2>\n",
    "    \n",
    "According to section **Representation of Time Sequence**, the input $x$ contains information about:\n",
    "    \n",
    "    [word_num_in_single_sentence, sentence_num, word_vector] = [Seq_len, batch, feature_len]\n",
    "    \n",
    "We extract temperal input $x_{t}$ which means the reading words in time epoch $t$ under parallel process:\n",
    "    \n",
    "    [sentence_num, word_vector] = [batch, feature_len]\n",
    "    \n",
    "According to section **RNN Structure**, the relationship between current temperal memory $h_{t}$ and previous memory $h_{t-1}$ is:\n",
    "    \n",
    "$$ h_{t} = x_{t-1}@W_{xh} + h_{t-1}@W_{hh} $$\n",
    "    \n",
    "The initial memory $h_{0}$ is set as vector **0** with shape of \n",
    "    \n",
    "    [batch, hidden_len]\n",
    "    \n",
    "which is also every memory's shape. In order to maintain this,the corresponding shapes of instances above are:\n",
    "    \n",
    "$x_{t-1}@W_{xh}$:\n",
    "    \n",
    "    [batch, feature_len] @ [hidden_len, feature_len].T = [batch, hidden_len]\n",
    "    \n",
    "$h_{t-1}@W_{hh}$:\n",
    "    \n",
    "    [batch, hidden_len] @ [hidden_len, hidden_len].T = [batch, hidden_len]\n",
    "    \n",
    "$ h_{t} = x_{t-1}@W_{xh} + h_{t-1}@W_{hh} $:\n",
    "    \n",
    "    [batch, hidden_len] + [batch, hidden_len] = [batch, hidden_len]\n",
    "    \n",
    "which is the same with initial memory $h_{0}$.\n",
    "    \n",
    "<div>\n",
    "<img src = 'RNN_4.png' style = 'zoom:40%'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474700a",
   "metadata": {},
   "source": [
    "#### Single RNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e61533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])\n",
      "\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#create RNN instance\n",
    "#para: input_size  -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "#para: num_layers  -> multipal layers of stacked RNN, default = 1\n",
    "rnn = nn.RNN(input_size = 20,hidden_size = 10, num_layers = 1)\n",
    "#check the parameters in RNN\n",
    "paras = rnn._parameters.keys()\n",
    "print(paras)\n",
    "print()\n",
    "#RNN can have multuple layers, l_0 here means layer l_0\n",
    "#weight_ih_l0: weights for input W_ih on layer l_0 -> [hidden_len, feature_len]\n",
    "print(rnn.weight_ih_l0.shape)\n",
    "#weight_hh_l0: weights for memory W_hh on layer l_0 -> [hidden_len, hidden_len]\n",
    "print(rnn.weight_hh_l0.shape)\n",
    "#bias_ih_l0: bias for input b_ih on layer l_0 -> [hidden_len]\n",
    "print(rnn.bias_ih_l0.shape)\n",
    "#bias_hh_l0: bias for memory b_hh on layer l_0 -> [hidden_len]\n",
    "print(rnn.bias_hh_l0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58c7e6",
   "metadata": {},
   "source": [
    "#### Multi- RNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7859f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', 'weight_ih_l1', 'weight_hh_l1', 'bias_ih_l1', 'bias_hh_l1'])\n",
      "\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#create an RNN instance with num_layers = 2\n",
    "#stack 2 RNN layers together\n",
    "#2nd RNN layer take the output of 1st RNN layer as input, and compute the result\n",
    "rnn2 = nn.RNN(input_size = 20,hidden_size = 10, num_layers = 2)\n",
    "paras = rnn2._parameters.keys()\n",
    "print(paras)\n",
    "print()\n",
    "#weight_ih_l0: weights for input W_ih on layer l_0 -> [hidden_len, feature_len]\n",
    "print(rnn2.weight_ih_l0.shape)\n",
    "#weight_hh_l0: weights for memory W_hh on layer l_0 -> [hidden_len, hidden_len]\n",
    "print(rnn2.weight_hh_l0.shape)\n",
    "#bias_ih_l0: bias for input b_ih on layer l_0 -> [hidden_len]\n",
    "print(rnn2.bias_ih_l0.shape)\n",
    "#bias_hh_l0: bias for memory b_hh on layer l_0 -> [hidden_len]\n",
    "print(rnn2.bias_hh_l0.shape)\n",
    "print()\n",
    "#weight_ih_l1: weights for input W_ih on layer l_1 -> [hidden_len, feature_len]\n",
    "#due to 2nd layer's input = 1st layer's output\n",
    "#the feature_len of 2nd RNN is length of 1st layer's output\n",
    "print(rnn2.weight_ih_l1.shape)\n",
    "#weight_hh_l1: weights for memory W_hh on layer l_1 -> [hidden_len, hidden_len]\n",
    "print(rnn2.weight_hh_l1.shape)\n",
    "#bias_ih_l1: bias for input b_ih on layer l_1 -> [hidden_len]\n",
    "print(rnn2.bias_ih_l1.shape)\n",
    "#bias_hh_l1: bias for memory b_hh on layer l_1 -> [hidden_len]\n",
    "print(rnn2.bias_hh_l1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c44be8",
   "metadata": {},
   "source": [
    "#### Output of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b837fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 10])\n",
      "torch.Size([1, 3, 10])\n",
      "\n",
      "torch.Size([5, 3, 10])\n",
      "torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "#input: [word_num_in_single_sentence, sentence_num, word_vector]\n",
    "#       [seq_len, b, feature_len]\n",
    "#i.e. 3 sentences, each sentence has 5 words, each word is represented 20-dimensional vector\n",
    "x = torch.randn(5,3,20)\n",
    "#h:   memory of every temperal epoch\n",
    "#out: stacked memory in time sequence\n",
    "#the paras of rnn() includes input x and initial h_0, but h_0 can be neglected\n",
    "out_rnn1, h_rnn1 = rnn(x)\n",
    "#out: [seq_len, b, hidden_len] -> stack[h1,h2,...,ht]\n",
    "print(out_rnn1.shape)\n",
    "#ht: [num_layers, b, hidden_size]\n",
    "print(h_rnn1.shape)\n",
    "print()\n",
    "\n",
    "out_rnn2, h_rnn2 = rnn2(x)\n",
    "print(out_rnn2.shape)\n",
    "print(h_rnn2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b3a58",
   "metadata": {},
   "source": [
    "#### nn.RNNCell\n",
    "<font size = 2>\n",
    "    \n",
    "The class **nn.RNN()** need the integral input with shape of:\n",
    "    \n",
    "    [word_num_in_single_sentence, sentence_num, word_vector]\n",
    "    =\n",
    "    [Seq_len, batch, feature_len]\n",
    "    \n",
    "However we can also give the input as time epoch manully, i.e. give input as:\n",
    "    \n",
    "    [sentence_num, word_vector]\n",
    "    \n",
    "by times of **word_num_in_single_sentence**.\n",
    "    \n",
    "This corresponds to eliminate the self-resurrection of RNN and replace that by user effort, which is illustrated below:\n",
    "    \n",
    "<div>\n",
    "<img src = 'RNN_5.png' style = 'zoom:40%'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9da53d",
   "metadata": {},
   "source": [
    "#### Single RNNCell Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5d1cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih', 'weight_hh', 'bias_ih', 'bias_hh'])\n",
      "torch.Size([5, 30])\n"
     ]
    }
   ],
   "source": [
    "#the intialization of RNNCell is the same as RNN but has no num_layers\n",
    "#as a result, use RNNCell to perform multi-layer RNN need multi-instantiation of RNNCell\n",
    "#para: input_size -> feature_len\n",
    "#para: hidden_size -> hidden_len\n",
    "cell1 = nn.RNNCell(input_size = 100, hidden_size = 30)\n",
    "cell_paras1 = cell1._parameters.keys()\n",
    "print(cell_paras1)\n",
    "#create input:\n",
    "#5 sentences, 10 words in each sentence, each word is represented in 100-dimensional vector(feature_len)\n",
    "cell_input_x = torch.randn(10,5,100)\n",
    "#initialize memory\n",
    "tmp_h_1 = torch.randn(5,30)\n",
    "#iterate on 0th dimension: dim of 'Seq_len'(time epoch) in [Seq_len, batch, feature_len]\n",
    "for x_t in cell_input_x:\n",
    "    #due to RNNCell need manully input along time epoch\n",
    "    #and the output of each RNNCell is a memory of single time epoch\n",
    "    tmp_h_1 = cell1(x_t, tmp_h_1)\n",
    "print(tmp_h_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72844c96",
   "metadata": {},
   "source": [
    "#### Multiple RNNCell Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f5114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih', 'weight_hh', 'bias_ih', 'bias_hh'])\n",
      "odict_keys(['weight_ih', 'weight_hh', 'bias_ih', 'bias_hh'])\n",
      "torch.Size([5, 30])\n",
      "torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "#manully instantiate 2 RNN layers\n",
    "cell1 = nn.RNNCell(input_size = 100, hidden_size = 30)\n",
    "#pay attention to the shape of 2nd layer\n",
    "#because the output of 1st layer will be input of 2nd layer\n",
    "cell2 = nn.RNNCell(input_size = 30, hidden_size = 20)\n",
    "cell_paras1 = cell1._parameters.keys()\n",
    "cell_paras2 = cell2._parameters.keys()\n",
    "print(cell_paras1)\n",
    "print(cell_paras2)\n",
    "#create input:\n",
    "#5 sentences, 10 words in each sentence, each word is represented in 100-dimensional vector(feature_len)\n",
    "cell_input_x = torch.randn(10,5,100)\n",
    "#initialize memory\n",
    "#compatibal with their own layers\n",
    "tmp_h_1 = torch.randn(5,30)\n",
    "tmp_h_2 = torch.randn(5,20)\n",
    "for x_t in cell_input_x:\n",
    "    tmp_h_1 = cell1(x_t,tmp_h_1)\n",
    "    #output of previous layer is input of current layer\n",
    "    tmp_h_2 = cell2(tmp_h_1, tmp_h_2)\n",
    "print(tmp_h_1.shape)\n",
    "print(tmp_h_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c476ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(3, size = 1)[0]\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6798aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "b = torch.zeros(1,1,4)\n",
    "x = torch.tensor(b.shape)[-1].item()\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a62d0655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(0,10,1).reshape(2,5)\n",
    "c = c.ravel()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aba0667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.54509634]]]\n",
      "[-0.54509634]\n"
     ]
    }
   ],
   "source": [
    "d = torch.randn(1,1,1).numpy()\n",
    "print(d)\n",
    "d = d.ravel()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58ae41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
